{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a8a366-be50-4d08-b4df-5546c012b5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-23 14:32:13,065] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "/opt/conda/lib/python3.10/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Enabling DeepSpeed FP16. Model parameters and inputs will be cast to `float16`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.2982280254364014 seconds\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | ViT              | 1.8 M  | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.248     Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('val_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('train_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('train_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "Epoch 1:\n",
      "Training Loss: 4.5000, Training Accuracy: 0.0247\n",
      "Validation Loss: 4.1980, Validation Accuracy: 0.0587\n",
      "Epoch 2:\n",
      "Training Loss: 4.2896, Training Accuracy: 0.0466\n",
      "Validation Loss: 4.0890, Validation Accuracy: 0.0766\n",
      "Epoch 3:\n",
      "Training Loss: 4.1491, Training Accuracy: 0.0678\n",
      "Validation Loss: 3.9856, Validation Accuracy: 0.0887\n",
      "Epoch 4:\n",
      "Training Loss: 4.0414, Training Accuracy: 0.0828\n",
      "Validation Loss: 3.8888, Validation Accuracy: 0.1091\n",
      "Epoch 5:\n",
      "Training Loss: 3.9354, Training Accuracy: 0.0981\n",
      "Validation Loss: 3.7756, Validation Accuracy: 0.1229\n",
      "Epoch 6:\n",
      "Training Loss: 3.8302, Training Accuracy: 0.1142\n",
      "Validation Loss: 3.6988, Validation Accuracy: 0.1330\n",
      "Epoch 7:\n",
      "Training Loss: 3.7412, Training Accuracy: 0.1277\n",
      "Validation Loss: 3.6236, Validation Accuracy: 0.1465\n",
      "Epoch 8:\n",
      "Training Loss: 3.6689, Training Accuracy: 0.1383\n",
      "Validation Loss: 3.5267, Validation Accuracy: 0.1614\n",
      "Epoch 9:\n",
      "Training Loss: 3.5738, Training Accuracy: 0.1522\n",
      "Validation Loss: 3.4854, Validation Accuracy: 0.1708\n",
      "Epoch 10:\n",
      "Training Loss: 3.4870, Training Accuracy: 0.1663\n",
      "Validation Loss: 3.3930, Validation Accuracy: 0.1863\n",
      "Epoch 11:\n",
      "Training Loss: 3.4619, Training Accuracy: 0.1721\n",
      "Validation Loss: 3.3580, Validation Accuracy: 0.1843\n",
      "Epoch 12:\n",
      "Training Loss: 3.3796, Training Accuracy: 0.1849\n",
      "Validation Loss: 3.2897, Validation Accuracy: 0.2063\n",
      "Epoch 13:\n",
      "Training Loss: 3.3203, Training Accuracy: 0.1950\n",
      "Validation Loss: 3.2238, Validation Accuracy: 0.2130\n",
      "Epoch 14:\n",
      "Training Loss: 3.2506, Training Accuracy: 0.2092\n",
      "Validation Loss: 3.1721, Validation Accuracy: 0.2283\n",
      "Epoch 15:\n",
      "Training Loss: 3.1939, Training Accuracy: 0.2202\n",
      "Validation Loss: 3.1431, Validation Accuracy: 0.2234\n",
      "Epoch 16:\n",
      "Training Loss: 3.1599, Training Accuracy: 0.2270\n",
      "Validation Loss: 3.0865, Validation Accuracy: 0.2370\n",
      "Epoch 17:\n",
      "Training Loss: 3.1093, Training Accuracy: 0.2344\n",
      "Validation Loss: 3.0448, Validation Accuracy: 0.2462\n",
      "Epoch 18:\n",
      "Training Loss: 3.0526, Training Accuracy: 0.2478\n",
      "Validation Loss: 2.9970, Validation Accuracy: 0.2548\n",
      "Epoch 19:\n",
      "Training Loss: 3.0171, Training Accuracy: 0.2508\n",
      "Validation Loss: 2.9479, Validation Accuracy: 0.2634\n",
      "Epoch 20:\n",
      "Training Loss: 2.9615, Training Accuracy: 0.2634\n",
      "Validation Loss: 2.9511, Validation Accuracy: 0.2632\n",
      "Epoch 21:\n",
      "Training Loss: 2.9371, Training Accuracy: 0.2680\n",
      "Validation Loss: 2.9225, Validation Accuracy: 0.2702\n",
      "Epoch 22:\n",
      "Training Loss: 2.8900, Training Accuracy: 0.2775\n",
      "Validation Loss: 2.8942, Validation Accuracy: 0.2704\n",
      "Epoch 23:\n",
      "Training Loss: 2.8722, Training Accuracy: 0.2804\n",
      "Validation Loss: 2.8469, Validation Accuracy: 0.2846\n",
      "Epoch 24:\n",
      "Training Loss: 2.8481, Training Accuracy: 0.2854\n",
      "Validation Loss: 2.8012, Validation Accuracy: 0.2892\n",
      "Epoch 25:\n",
      "Training Loss: 2.7936, Training Accuracy: 0.2949\n",
      "Validation Loss: 2.7618, Validation Accuracy: 0.2984\n",
      "Epoch 26:\n",
      "Training Loss: 2.7449, Training Accuracy: 0.3036\n",
      "Validation Loss: 2.7315, Validation Accuracy: 0.3037\n",
      "Epoch 27:\n",
      "Training Loss: 2.7199, Training Accuracy: 0.3093\n",
      "Validation Loss: 2.7270, Validation Accuracy: 0.3012\n",
      "Epoch 28:\n",
      "Training Loss: 2.7090, Training Accuracy: 0.3123\n",
      "Validation Loss: 2.6903, Validation Accuracy: 0.3123\n",
      "Epoch 29:\n",
      "Training Loss: 2.6814, Training Accuracy: 0.3169\n",
      "Validation Loss: 2.6830, Validation Accuracy: 0.3187\n",
      "Epoch 30:\n",
      "Training Loss: 2.6495, Training Accuracy: 0.3208\n",
      "Validation Loss: 2.6653, Validation Accuracy: 0.3193\n",
      "Epoch 31:\n",
      "Training Loss: 2.6312, Training Accuracy: 0.3270\n",
      "Validation Loss: 2.6134, Validation Accuracy: 0.3303\n",
      "Epoch 32:\n",
      "Training Loss: 2.6056, Training Accuracy: 0.3323\n",
      "Validation Loss: 2.5740, Validation Accuracy: 0.3398\n",
      "Epoch 33:\n",
      "Training Loss: 2.5663, Training Accuracy: 0.3382\n",
      "Validation Loss: 2.5606, Validation Accuracy: 0.3415\n",
      "Epoch 34:\n",
      "Training Loss: 2.5310, Training Accuracy: 0.3471\n",
      "Validation Loss: 2.5335, Validation Accuracy: 0.3450\n",
      "Epoch 35:\n",
      "Training Loss: 2.5022, Training Accuracy: 0.3539\n",
      "Validation Loss: 2.5285, Validation Accuracy: 0.3496\n",
      "Epoch 36:\n",
      "Training Loss: 2.4904, Training Accuracy: 0.3536\n",
      "Validation Loss: 2.5046, Validation Accuracy: 0.3537\n",
      "Epoch 37:\n",
      "Training Loss: 2.4622, Training Accuracy: 0.3627\n",
      "Validation Loss: 2.4808, Validation Accuracy: 0.3593\n",
      "Epoch 38:\n",
      "Training Loss: 2.4334, Training Accuracy: 0.3649\n",
      "Validation Loss: 2.4679, Validation Accuracy: 0.3584\n",
      "Epoch 39:\n",
      "Training Loss: 2.4230, Training Accuracy: 0.3702\n",
      "Validation Loss: 2.4518, Validation Accuracy: 0.3678\n",
      "Epoch 40:\n",
      "Training Loss: 2.4102, Training Accuracy: 0.3728\n",
      "Validation Loss: 2.4287, Validation Accuracy: 0.3709\n",
      "Epoch 41:\n",
      "Training Loss: 2.3777, Training Accuracy: 0.3793\n",
      "Validation Loss: 2.4252, Validation Accuracy: 0.3688\n",
      "Epoch 42:\n",
      "Training Loss: 2.3446, Training Accuracy: 0.3865\n",
      "Validation Loss: 2.3878, Validation Accuracy: 0.3768\n",
      "Epoch 43:\n",
      "Training Loss: 2.3150, Training Accuracy: 0.3940\n",
      "Validation Loss: 2.3666, Validation Accuracy: 0.3812\n",
      "Epoch 44:\n",
      "Training Loss: 2.2928, Training Accuracy: 0.3986\n",
      "Validation Loss: 2.3868, Validation Accuracy: 0.3785\n",
      "Epoch 45:\n",
      "Training Loss: 2.2806, Training Accuracy: 0.3986\n",
      "Validation Loss: 2.3533, Validation Accuracy: 0.3900\n",
      "Epoch 46:\n",
      "Training Loss: 2.2735, Training Accuracy: 0.4033\n",
      "Validation Loss: 2.3350, Validation Accuracy: 0.3894\n",
      "Epoch 47:\n",
      "Training Loss: 2.2438, Training Accuracy: 0.4102\n",
      "Validation Loss: 2.3019, Validation Accuracy: 0.3974\n",
      "Epoch 48:\n",
      "Training Loss: 2.2321, Training Accuracy: 0.4126\n",
      "Validation Loss: 2.3293, Validation Accuracy: 0.3904\n",
      "Epoch 49:\n",
      "Training Loss: 2.2104, Training Accuracy: 0.4126\n",
      "Validation Loss: 2.3194, Validation Accuracy: 0.3986\n",
      "Epoch 50:\n",
      "Training Loss: 2.1812, Training Accuracy: 0.4212\n",
      "Validation Loss: 2.2778, Validation Accuracy: 0.4006\n",
      "Epoch 51:\n",
      "Training Loss: 2.1728, Training Accuracy: 0.4209\n",
      "Validation Loss: 2.2880, Validation Accuracy: 0.3990\n",
      "Epoch 52:\n",
      "Training Loss: 2.1516, Training Accuracy: 0.4284\n",
      "Validation Loss: 2.2471, Validation Accuracy: 0.4135\n",
      "Epoch 53:\n",
      "Training Loss: 2.1433, Training Accuracy: 0.4317\n",
      "Validation Loss: 2.2512, Validation Accuracy: 0.4128\n",
      "Epoch 54:\n",
      "Training Loss: 2.1045, Training Accuracy: 0.4372\n",
      "Validation Loss: 2.2217, Validation Accuracy: 0.4192\n",
      "Epoch 55:\n",
      "Training Loss: 2.0879, Training Accuracy: 0.4411\n",
      "Validation Loss: 2.2243, Validation Accuracy: 0.4193\n",
      "Epoch 56:\n",
      "Training Loss: 2.0755, Training Accuracy: 0.4446\n",
      "Validation Loss: 2.2150, Validation Accuracy: 0.4144\n",
      "Epoch 57:\n",
      "Training Loss: 2.0590, Training Accuracy: 0.4483\n",
      "Validation Loss: 2.2013, Validation Accuracy: 0.4217\n",
      "Epoch 58:\n",
      "Training Loss: 2.0412, Training Accuracy: 0.4520\n",
      "Validation Loss: 2.1943, Validation Accuracy: 0.4233\n",
      "Epoch 59:\n",
      "Training Loss: 2.0332, Training Accuracy: 0.4545\n",
      "Validation Loss: 2.1740, Validation Accuracy: 0.4270\n",
      "Epoch 60:\n",
      "Training Loss: 2.0066, Training Accuracy: 0.4613\n",
      "Validation Loss: 2.1531, Validation Accuracy: 0.4336\n",
      "Epoch 61:\n",
      "Training Loss: 1.9827, Training Accuracy: 0.4650\n",
      "Validation Loss: 2.1454, Validation Accuracy: 0.4387\n",
      "Epoch 62:\n",
      "Training Loss: 1.9580, Training Accuracy: 0.4726\n",
      "Validation Loss: 2.1340, Validation Accuracy: 0.4391\n",
      "Epoch 63:\n",
      "Training Loss: 1.9520, Training Accuracy: 0.4735\n",
      "Validation Loss: 2.1134, Validation Accuracy: 0.4416\n",
      "Epoch 64:\n",
      "Training Loss: 1.9238, Training Accuracy: 0.4809\n",
      "Validation Loss: 2.1128, Validation Accuracy: 0.4474\n",
      "Epoch 65:\n",
      "Training Loss: 1.9113, Training Accuracy: 0.4819\n",
      "Validation Loss: 2.1227, Validation Accuracy: 0.4450\n",
      "Epoch 66:\n",
      "Training Loss: 1.9101, Training Accuracy: 0.4819\n",
      "Validation Loss: 2.1045, Validation Accuracy: 0.4457\n",
      "Epoch 67:\n",
      "Training Loss: 1.8945, Training Accuracy: 0.4838\n",
      "Validation Loss: 2.0688, Validation Accuracy: 0.4508\n",
      "Epoch 68:\n",
      "Training Loss: 1.8649, Training Accuracy: 0.4926\n",
      "Validation Loss: 2.0624, Validation Accuracy: 0.4549\n",
      "Epoch 69:\n",
      "Training Loss: 1.8439, Training Accuracy: 0.4981\n",
      "Validation Loss: 2.0676, Validation Accuracy: 0.4530\n",
      "Epoch 70:\n",
      "Training Loss: 1.8373, Training Accuracy: 0.5019\n",
      "Validation Loss: 2.0748, Validation Accuracy: 0.4499\n",
      "Epoch 71:\n",
      "Training Loss: 1.8145, Training Accuracy: 0.5019\n",
      "Validation Loss: 2.0720, Validation Accuracy: 0.4547\n",
      "Epoch 72:\n",
      "Training Loss: 1.8253, Training Accuracy: 0.5026\n",
      "Validation Loss: 2.0548, Validation Accuracy: 0.4555\n",
      "Epoch 73:\n",
      "Training Loss: 1.8152, Training Accuracy: 0.5035\n",
      "Validation Loss: 2.0457, Validation Accuracy: 0.4621\n",
      "Epoch 74:\n",
      "Training Loss: 1.7921, Training Accuracy: 0.5090\n",
      "Validation Loss: 2.0023, Validation Accuracy: 0.4703\n",
      "Epoch 75:\n",
      "Training Loss: 1.7692, Training Accuracy: 0.5142\n",
      "Validation Loss: 2.0345, Validation Accuracy: 0.4646\n",
      "Epoch 76:\n",
      "Training Loss: 1.7493, Training Accuracy: 0.5185\n",
      "Validation Loss: 2.0264, Validation Accuracy: 0.4676\n",
      "Epoch 77:\n",
      "Training Loss: 1.7414, Training Accuracy: 0.5209\n",
      "Validation Loss: 2.0107, Validation Accuracy: 0.4701\n",
      "Epoch 78:\n",
      "Training Loss: 1.7181, Training Accuracy: 0.5258\n",
      "Validation Loss: 1.9994, Validation Accuracy: 0.4716\n",
      "Epoch 79:\n",
      "Training Loss: 1.6999, Training Accuracy: 0.5293\n",
      "Validation Loss: 2.0020, Validation Accuracy: 0.4752\n",
      "Epoch 80:\n",
      "Training Loss: 1.6819, Training Accuracy: 0.5332\n",
      "Validation Loss: 1.9799, Validation Accuracy: 0.4794\n",
      "Epoch 81:\n",
      "Training Loss: 1.6817, Training Accuracy: 0.5369\n",
      "Validation Loss: 2.0306, Validation Accuracy: 0.4682\n",
      "Epoch 82:\n",
      "Training Loss: 1.6775, Training Accuracy: 0.5340\n",
      "Validation Loss: 1.9881, Validation Accuracy: 0.4748\n",
      "Epoch 83:\n",
      "Training Loss: 1.6527, Training Accuracy: 0.5420\n",
      "Validation Loss: 1.9694, Validation Accuracy: 0.4779\n",
      "Epoch 84:\n",
      "Training Loss: 1.6489, Training Accuracy: 0.5399\n",
      "Validation Loss: 1.9778, Validation Accuracy: 0.4826\n",
      "Epoch 85:\n",
      "Training Loss: 1.6284, Training Accuracy: 0.5476\n",
      "Validation Loss: 1.9597, Validation Accuracy: 0.4802\n",
      "Epoch 86:\n",
      "Training Loss: 1.6092, Training Accuracy: 0.5504\n",
      "Validation Loss: 1.9672, Validation Accuracy: 0.4829\n",
      "Epoch 87:\n",
      "Training Loss: 1.5864, Training Accuracy: 0.5565\n",
      "Validation Loss: 1.9547, Validation Accuracy: 0.4844\n",
      "Epoch 88:\n",
      "Training Loss: 1.5711, Training Accuracy: 0.5633\n",
      "Validation Loss: 1.9602, Validation Accuracy: 0.4860\n",
      "Epoch 89:\n",
      "Training Loss: 1.5644, Training Accuracy: 0.5642\n",
      "Validation Loss: 1.9375, Validation Accuracy: 0.4880\n",
      "Epoch 90:\n",
      "Training Loss: 1.5438, Training Accuracy: 0.5682\n",
      "Validation Loss: 1.9536, Validation Accuracy: 0.4855\n",
      "Epoch 91:\n",
      "Training Loss: 1.5396, Training Accuracy: 0.5685\n",
      "Validation Loss: 1.9606, Validation Accuracy: 0.4892\n",
      "Epoch 92:\n",
      "Training Loss: 1.5328, Training Accuracy: 0.5704\n",
      "Validation Loss: 1.9232, Validation Accuracy: 0.4946\n",
      "Epoch 93:\n",
      "Training Loss: 1.5205, Training Accuracy: 0.5739\n",
      "Validation Loss: 1.9464, Validation Accuracy: 0.4903\n",
      "Epoch 94:\n",
      "Training Loss: 1.5165, Training Accuracy: 0.5718\n",
      "Validation Loss: 1.9431, Validation Accuracy: 0.4944\n",
      "Epoch 95:\n",
      "Training Loss: 1.5042, Training Accuracy: 0.5764\n",
      "Validation Loss: 1.9322, Validation Accuracy: 0.4911\n",
      "Epoch 96:\n",
      "Training Loss: 1.4899, Training Accuracy: 0.5793\n",
      "Validation Loss: 1.9474, Validation Accuracy: 0.4878\n",
      "Epoch 97:\n",
      "Training Loss: 1.4659, Training Accuracy: 0.5843\n",
      "Validation Loss: 1.9052, Validation Accuracy: 0.4971\n",
      "Epoch 98:\n",
      "Training Loss: 1.4496, Training Accuracy: 0.5911\n",
      "Validation Loss: 1.9371, Validation Accuracy: 0.4935\n",
      "Epoch 99:\n",
      "Training Loss: 1.4453, Training Accuracy: 0.5917\n",
      "Validation Loss: 1.9277, Validation Accuracy: 0.4950\n",
      "Epoch 100:\n",
      "Training Loss: 1.4235, Training Accuracy: 0.5971\n",
      "Validation Loss: 1.9520, Validation Accuracy: 0.4943\n",
      "Epoch 101:\n",
      "Training Loss: 1.4080, Training Accuracy: 0.6017\n",
      "Validation Loss: 1.9125, Validation Accuracy: 0.4974\n",
      "Epoch 102:\n",
      "Training Loss: 1.3974, Training Accuracy: 0.6014\n",
      "Validation Loss: 1.9069, Validation Accuracy: 0.5062\n",
      "Epoch 103:\n",
      "Training Loss: 1.3897, Training Accuracy: 0.6059\n",
      "Validation Loss: 1.9130, Validation Accuracy: 0.5020\n",
      "Epoch 104:\n",
      "Training Loss: 1.3796, Training Accuracy: 0.6066\n",
      "Validation Loss: 1.9045, Validation Accuracy: 0.5116\n",
      "Epoch 105:\n",
      "Training Loss: 1.3637, Training Accuracy: 0.6096\n",
      "Validation Loss: 1.9306, Validation Accuracy: 0.5000\n",
      "Epoch 106:\n",
      "Training Loss: 1.3573, Training Accuracy: 0.6117\n",
      "Validation Loss: 1.9009, Validation Accuracy: 0.5060\n",
      "Epoch 107:\n",
      "Training Loss: 1.3474, Training Accuracy: 0.6163\n",
      "Validation Loss: 1.9077, Validation Accuracy: 0.5064\n",
      "Epoch 108:\n",
      "Training Loss: 1.3304, Training Accuracy: 0.6190\n",
      "Validation Loss: 1.9273, Validation Accuracy: 0.5063\n",
      "Epoch 109:\n",
      "Training Loss: 1.3194, Training Accuracy: 0.6248\n",
      "Validation Loss: 1.9137, Validation Accuracy: 0.5061\n",
      "CPU times: user 10.1 s, sys: 1.28 s, total: 11.3 s\n",
      "Wall time: 22min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python ViT_Classification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54374a4b-9f56-48c3-b3f3-d1591305c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
